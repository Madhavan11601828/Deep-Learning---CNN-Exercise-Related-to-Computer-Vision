# Deep Learning - CNN Architecture Exercise Related to Computer Vision

__Introduction:__

Deep neural networks have tremendous potential to learn complex non-linear functions, patterns, and representations. This includes real-world applications like image categorization and classification and the very popular concept of image artistic style transfer. Computer vision is all about the art and science of making machines understand high-level useful patterns and representations from images and videos so that it would be able to make intelligent decisions similar to what a human would do upon observing its surroundings. 

Convolutional neural networks or CNNs are extensively used for automated feature extraction in images.  In fact, CNNs are similar to the general deep neural networks, but with explicit assumption of input being a data set where which the location of a feature is relevant can be attempted via CNNs  like image, but not limited to then. Others examples are:
- ***Time series***: your data is well ordered. A time series problem would make a 1–d convolution the right choice.
- ***Weather***: Build a map of current weather conditions (location-based values, but not actual images). Add another dimension to it for the previous weather maps (in order) and you have a 4–d convolution problem to predict the weather.

This notebook explore convolutional neural networks through the task of image classification using publicly dataset  CIFAR-10. We will utilize our understanding of CNNs to then take on the task of style transfer and understand how neural networks can be used to understand high-level features. Through this notebook, we cover the following topics:
- Image classification use CNNs from scratch
- Transfer learning: image classification using pretrained models
- Neural style transfer using CNNs

For an in-depth understanding of CNNs applied for visual recognition take look on the [Stanford course material](http://cs231n.github.io/convolutional-networks). Let us see a little brief overview of its key concepts:
- ***A CNN is made up of Layers***: Every Layer has a simple API: It transforms an input 3D volume to an output 3D volume with some differentiable function that may or may not have parameters. the main layers are:
    - ***Convolutional Layer***: Is a set of slides or convolves learnable filters, also known as kernels or convolution matrix, to help capture spatial features. These cover the width, height and the full depth (color range) of the image. During the forward pass, we slide the filter across the width and the height of the image while computing the dot product between the filter attributes and the input at any position. The output is a two-dimensional activation map from each filter, which are then stacked to get the final output.
    - ***Pooling Layer***: These are basically down-sampling layers used to reduce spatial size and number of parameters by apply functions such as max, average, L2-norm, and so on. These layers also help in controlling overfitting.  These layers are insert in between conv layers or in the end of a sequence of them.
    - ***Fully Connected Layer***: This layer helps perform the tasks of classification. It is similar to fully connected layers in general neural networks. These have full connections to all neurons in the previous layer and can followed by a Dropout to help to reduce overfit.<p>
- ***Parameter Sharing***: Conv layers use same set of weights across the filters thus reducing the overall number of parameters required.

CNNs have gone through tremendous research and advancements have led to more complex and power architectures, like VGG-16, VGG-19, Inception V3, and many models that are more interesting.

Let's start our studies:
![image](https://github.com/Madhavan11601828/Deep-Learning---CNN-Exercise-Related-to-Computer-Vision/blob/main/ProcessOfconvnet.jpeg)


<h1>The Process of Execution<span class="tocSkip"></span></h1>
<div class="toc"><ul class="toc-item"><li><span><a href="#Preparing-environment-and-uploading-data" data-toc-modified-id="Preparing-environment-and-uploading-data-1"><span class="toc-item-num">1&nbsp;&nbsp;</span>Preparing environment and uploading data</a></span><ul class="toc-item"><li><span><a href="#Import-Packages" data-toc-modified-id="Import-Packages-1.1"><span class="toc-item-num">1.1&nbsp;&nbsp;</span>Import Packages</a></span></li></ul></li><li><span><a href="#Load-and-Prepare-Data" data-toc-modified-id="Load-and-Prepare-Data-2"><span class="toc-item-num">2&nbsp;&nbsp;</span>Load and Prepare Data</a></span><ul class="toc-item"><li><span><a href="#Scaling-the-Data" data-toc-modified-id="Scaling-the-Data-2.1"><span class="toc-item-num">2.1&nbsp;&nbsp;</span>Scaling the Data</a></span></li><li><span><a href="#Prepare-the-target-variable" data-toc-modified-id="Prepare-the-target-variable-2.2"><span class="toc-item-num">2.2&nbsp;&nbsp;</span>Prepare the target variable</a></span></li><li><span><a href="#Data-Augmentation" data-toc-modified-id="Data-Augmentation-2.3"><span class="toc-item-num">2.3&nbsp;&nbsp;</span>Data Augmentation</a></span></li><li><span><a href="#Set-Global-Variables-and-Seed" data-toc-modified-id="Set-Global-Variables-and-Seed-2.4"><span class="toc-item-num">2.4&nbsp;&nbsp;</span>Set Global Variables and Seed</a></span></li></ul></li><li><span><a href="#Image-Multiclassifier-using-CNNs-from-scratch" data-toc-modified-id="Image-Multiclassifier-using-CNNs-from-scratch-3"><span class="toc-item-num">3&nbsp;&nbsp;</span>Image Multiclassifier using CNNs from scratch</a></span><ul class="toc-item"><li><span><a href="#Create-the-CNN-Model" data-toc-modified-id="Create-the-CNN-Model-3.1"><span class="toc-item-num">3.1&nbsp;&nbsp;</span>Create the CNN Model</a></span></li><li><span><a href="#Visualize-the-network-architecture" data-toc-modified-id="Visualize-the-network-architecture-3.2"><span class="toc-item-num">3.2&nbsp;&nbsp;</span>Visualize the network architecture</a></span></li><li><span><a href="#Final-evaluation-of-the-model" data-toc-modified-id="Final-evaluation-of-the-model-3.3"><span class="toc-item-num">3.3&nbsp;&nbsp;</span>Final evaluation of the model</a></span></li><li><span><a href="#Predict-class-of-image-in-practice" data-toc-modified-id="Predict-class-of-image-in-practice-3.4"><span class="toc-item-num">3.4&nbsp;&nbsp;</span>Predict class of image in practice</a></span></li><li><span><a href="#Model-Interpretation" data-toc-modified-id="Model-Interpretation-3.5"><span class="toc-item-num">3.5&nbsp;&nbsp;</span>Model Interpretation</a></span></li></ul></li><li><span><a href="#CNN-with-Pre-Trained-Models" data-toc-modified-id="CNN-with-Pre-Trained-Models-4"><span class="toc-item-num">4&nbsp;&nbsp;</span>CNN with Pre-Trained Models</a></span><ul class="toc-item"><li><span><a href="#Create-The-Model-by-a-Pre-Trained-Model" data-toc-modified-id="Create-The-Model-by-a-Pre-Trained-Model-4.1"><span class="toc-item-num">4.1&nbsp;&nbsp;</span>Create The Model by a Pre-Trained Model</a></span></li><li><span><a href="#Final-evaluation-of-the-model" data-toc-modified-id="Final-evaluation-of-the-model-4.2"><span class="toc-item-num">4.2&nbsp;&nbsp;</span>Final evaluation of the model</a></span></li><li><span><a href="#Predict-class-of-image-in-CNN-Pre-Trained-Classifier" data-toc-modified-id="Predict-class-of-image-in-CNN-Pre-Trained-Classifier-4.3"><span class="toc-item-num">4.3&nbsp;&nbsp;</span>Predict class of image in CNN Pre-Trained Classifier</a></span></li></ul></li><li><span><a href="#Conclusion" data-toc-modified-id="Conclusion-5"><span class="toc-item-num">5&nbsp;&nbsp;</span>Conclusion</a></span></li></ul></div>


# Load and Prepare Data
The CIFAR-10 dataset consists of 60000 32x32 color images in 10 classes, with 6000 images per class. There are 50000 training images divided into five training batches and one test batch, each with 10000 images. .

The dataset was collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton and is available at cs.totonto.edu as well as through the datasets module in keras through the keras.datasets module.

Similar to any Machine Learning algorithm, neural networks also require the input data to be certain shape, size, and type. Therefore, before we reach the modeling step, the first thing is to preprocess the data itself. The following snippet gets the datasets from the different batches files. First, each file need to be unpickled, then the independent variables and dependent variable are separate, next the dependent variables are separated in their respective colors channels and reshape according the size of the image, then the data are converted to a numpy array and transpose to reorganize the data from 3,32,32 to 32,32,3. Finally, the data is append to can used as a unique dataset.
